{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_423_Keras_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arewelearningyet/neuralnetworks/blob/master/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Neural Network Framework (Keras)\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
        "\n",
        "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
        "- Normalize the data (all features should have roughly the same scale)\n",
        "- Import the type of model and layers that you will need from Keras.\n",
        "- Instantiate a model object and use `model.add()` to add layers to your model\n",
        "- Since this is a regression model you will have a single output node in the final layer.\n",
        "- Use activation functions that are appropriate for this task\n",
        "- Compile your model\n",
        "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
        "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
        "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NLTAR87uYJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2160ffaf-3585-4b71-8009-7723f03cf2f8"
      },
      "source": [
        "'''IMPORT boston_housing from KERAS lib '''\n",
        "\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = boston_housing.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w51TPQAeJeG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' NORMALIZE the data [all feats roughly same scale] '''\n",
        "\n",
        "import sklearn.preprocessing\n",
        "\n",
        "normalizer = sklearn.preprocessing.Normalizer()\n",
        "normalizer.fit(xtrain)\n",
        "\n",
        "xtrain = normalizer.transform(xtrain)\n",
        "xtest = normalizer.transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnp34BxWJtwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9f1a7afb-f6a5-4eca-cce3-b29d6fafa83c"
      },
      "source": [
        "xtrain.shape, ytrain.shape, xtest.shape, ytest.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (404,), (102, 13), (102,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL13TcFJJ4Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' IMPORT the type of MODEL and LAYERS that you will need from KERAS '''\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9gXdt4iKXPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f20abb9e-a569-4c61-a93c-499d3869414a"
      },
      "source": [
        "''' INSTANTIATE a MODEL OBJECT and use model.add() to add layers to your model '''\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(13,)))\n",
        "model.add(tf.keras.layers.Dense(32, activation='selu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='selu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='selu'))\n",
        "model.add(tf.keras.layers.Dense(32, activation='selu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='selu'))\n",
        "\n",
        "''' since this is a regrsn model, has a single output node in the final layer '''\n",
        "\n",
        "tf.keras.layers.Dense(1, activation='selu') \n",
        "\n",
        "''' use activation functions that are appropriate for this task '''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' use activation functions that are appropriate for this task '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjaIgQ0tLPQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' compile your model '''\n",
        "model.compile(loss='mse', optimizer='nadam', metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QkmKyJqLY1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d028c586-b1f7-4c4f-d44c-769bffdc432c"
      },
      "source": [
        "''' fit your model and report it's accuracy in terms of mean squared error '''\n",
        "\n",
        "model.fit(xtrain, ytrain, epochs=200, validation_data=(xtest, ytest))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 577.8455 - mse: 581.5352 - val_loss: 679.9955 - val_mse: 596.7523\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 544.7448 - mse: 545.1611 - val_loss: 611.2643 - val_mse: 532.6915\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 449.2828 - mse: 447.4741 - val_loss: 440.2330 - val_mse: 375.1362\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 258.7245 - mse: 263.0925 - val_loss: 209.8606 - val_mse: 172.0582\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 127.7732 - mse: 125.5243 - val_loss: 119.5266 - val_mse: 102.7316\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 94.2865 - mse: 93.5150 - val_loss: 100.6952 - val_mse: 84.7427\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 83.3908 - mse: 81.8064 - val_loss: 92.4036 - val_mse: 78.0416\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 77.8625 - mse: 77.4798 - val_loss: 93.6880 - val_mse: 76.1829\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 76.8540 - mse: 75.2541 - val_loss: 89.7823 - val_mse: 73.2478\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 72.8328 - mse: 73.3408 - val_loss: 91.4815 - val_mse: 72.7012\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 71.9277 - mse: 71.2997 - val_loss: 83.4244 - val_mse: 68.4185\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 69.0170 - mse: 69.6354 - val_loss: 81.8003 - val_mse: 66.2709\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 66.5113 - mse: 67.8546 - val_loss: 82.3009 - val_mse: 64.7731\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 67.2157 - mse: 66.4283 - val_loss: 80.3878 - val_mse: 62.7938\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 65.5236 - mse: 64.4715 - val_loss: 75.5711 - val_mse: 60.9547\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 65.2079 - mse: 64.0317 - val_loss: 75.9368 - val_mse: 59.7040\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 62.4248 - mse: 63.1054 - val_loss: 76.2489 - val_mse: 58.9591\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 61.4036 - mse: 62.6442 - val_loss: 79.7317 - val_mse: 59.5971\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 61.1266 - mse: 61.7170 - val_loss: 74.5000 - val_mse: 57.7785\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 61.0506 - mse: 61.5977 - val_loss: 78.2984 - val_mse: 58.4595\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 60.3245 - mse: 61.0046 - val_loss: 76.1081 - val_mse: 57.4237\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 59.8560 - mse: 60.8188 - val_loss: 77.7253 - val_mse: 57.7138\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 59.9973 - mse: 60.1903 - val_loss: 73.3810 - val_mse: 56.5441\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 61.6397 - mse: 59.9553 - val_loss: 75.1644 - val_mse: 56.4930\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 58.3719 - mse: 59.5398 - val_loss: 76.4155 - val_mse: 56.6404\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 58.2383 - mse: 59.0277 - val_loss: 77.0414 - val_mse: 56.6623\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 59.2064 - mse: 59.3774 - val_loss: 75.4869 - val_mse: 56.0175\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 60.0933 - mse: 58.3302 - val_loss: 72.5865 - val_mse: 55.5102\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 56.7942 - mse: 57.9687 - val_loss: 82.2521 - val_mse: 58.6918\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 58.9333 - mse: 57.9647 - val_loss: 72.1938 - val_mse: 55.1834\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 57.2196 - mse: 57.9919 - val_loss: 77.7825 - val_mse: 56.2666\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 56.8724 - mse: 57.3059 - val_loss: 74.6673 - val_mse: 55.0368\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 56.0609 - mse: 56.9302 - val_loss: 78.8473 - val_mse: 56.4821\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 58.2595 - mse: 56.7434 - val_loss: 72.8591 - val_mse: 54.5018\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 55.8170 - mse: 56.4686 - val_loss: 78.5778 - val_mse: 56.1866\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 56.3375 - mse: 56.6660 - val_loss: 74.0497 - val_mse: 54.4831\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 55.9290 - mse: 55.8737 - val_loss: 78.0717 - val_mse: 55.8009\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 54.5320 - mse: 55.6559 - val_loss: 77.4442 - val_mse: 55.4007\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 54.8923 - mse: 55.9038 - val_loss: 74.4864 - val_mse: 54.1922\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 55.1236 - mse: 55.4430 - val_loss: 73.1360 - val_mse: 53.7369\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 54.8260 - mse: 54.8418 - val_loss: 71.6408 - val_mse: 53.4249\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 53.9105 - mse: 54.2560 - val_loss: 72.8367 - val_mse: 53.3919\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 55.1421 - mse: 54.2659 - val_loss: 70.1713 - val_mse: 53.1980\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 53.9261 - mse: 54.0587 - val_loss: 77.0787 - val_mse: 54.7402\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 52.8515 - mse: 53.1496 - val_loss: 69.8537 - val_mse: 52.8745\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 52.6247 - mse: 53.4590 - val_loss: 73.0645 - val_mse: 53.0250\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 53.4221 - mse: 53.6935 - val_loss: 71.8867 - val_mse: 52.6583\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 53.4291 - mse: 52.6871 - val_loss: 73.0190 - val_mse: 52.8472\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 51.7175 - mse: 52.5945 - val_loss: 77.4086 - val_mse: 54.6332\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 54.2434 - mse: 52.3994 - val_loss: 68.5132 - val_mse: 52.0234\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 52.0720 - mse: 51.7220 - val_loss: 72.8463 - val_mse: 52.4743\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 52.4165 - mse: 51.1282 - val_loss: 67.2049 - val_mse: 51.9137\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 51.2974 - mse: 52.0485 - val_loss: 75.5930 - val_mse: 53.5343\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 51.3179 - mse: 51.7624 - val_loss: 73.3579 - val_mse: 52.4155\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 50.1395 - mse: 50.1299 - val_loss: 66.9391 - val_mse: 50.7850\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 49.7989 - mse: 50.2704 - val_loss: 68.7746 - val_mse: 50.5726\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 49.3351 - mse: 49.9874 - val_loss: 68.5246 - val_mse: 50.3339\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 49.2604 - mse: 49.6534 - val_loss: 68.4108 - val_mse: 50.1406\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 50.0916 - mse: 48.9867 - val_loss: 65.3912 - val_mse: 49.5833\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 51.2665 - mse: 48.7961 - val_loss: 63.1644 - val_mse: 52.3238\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 47.9187 - mse: 48.4580 - val_loss: 66.8303 - val_mse: 49.0895\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 48.7364 - mse: 47.0074 - val_loss: 62.0560 - val_mse: 51.8214\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 47.6421 - mse: 48.6547 - val_loss: 67.6075 - val_mse: 49.0233\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 47.2879 - mse: 46.8850 - val_loss: 66.5813 - val_mse: 48.5248\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 47.8781 - mse: 46.6987 - val_loss: 60.6616 - val_mse: 47.8203\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 45.7472 - mse: 45.9514 - val_loss: 62.3875 - val_mse: 46.8052\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 44.4869 - mse: 45.2347 - val_loss: 66.1571 - val_mse: 47.9093\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 46.0598 - mse: 45.4478 - val_loss: 58.2813 - val_mse: 46.1076\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 44.2800 - mse: 44.3047 - val_loss: 59.5298 - val_mse: 45.1837\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 42.9517 - mse: 43.3633 - val_loss: 58.9043 - val_mse: 44.6243\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 42.8765 - mse: 43.3661 - val_loss: 63.2647 - val_mse: 46.1553\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 43.7274 - mse: 44.1840 - val_loss: 64.7014 - val_mse: 47.0100\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 42.1230 - mse: 41.7689 - val_loss: 54.2601 - val_mse: 42.8221\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 41.9887 - mse: 41.9839 - val_loss: 53.3022 - val_mse: 42.1790\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 40.2102 - mse: 40.3817 - val_loss: 52.6829 - val_mse: 41.3591\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 38.9062 - mse: 39.5530 - val_loss: 52.0039 - val_mse: 40.6209\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 39.5520 - mse: 39.5160 - val_loss: 51.6559 - val_mse: 40.0309\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 38.2223 - mse: 38.5124 - val_loss: 49.8824 - val_mse: 39.2331\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 37.4399 - mse: 37.9830 - val_loss: 52.3284 - val_mse: 39.9663\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 36.7064 - mse: 37.4134 - val_loss: 58.6568 - val_mse: 44.1722\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 36.3642 - mse: 35.7058 - val_loss: 45.3756 - val_mse: 38.8821\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 38.6469 - mse: 37.2627 - val_loss: 48.9652 - val_mse: 45.9164\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 35.9807 - mse: 35.9184 - val_loss: 43.6782 - val_mse: 35.8848\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 33.4839 - mse: 33.8211 - val_loss: 45.4636 - val_mse: 36.0896\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 34.5127 - mse: 34.8253 - val_loss: 43.3106 - val_mse: 39.1359\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 35.8434 - mse: 36.2650 - val_loss: 43.2180 - val_mse: 34.9553\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 34.0584 - mse: 33.7989 - val_loss: 40.3098 - val_mse: 33.7938\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 33.1388 - mse: 33.5994 - val_loss: 42.1025 - val_mse: 34.2433\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 33.5279 - mse: 33.3807 - val_loss: 38.9078 - val_mse: 33.2725\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 31.6609 - mse: 31.9442 - val_loss: 38.8258 - val_mse: 32.6840\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 32.7578 - mse: 31.5196 - val_loss: 42.2941 - val_mse: 39.3070\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 32.7567 - mse: 32.3887 - val_loss: 37.8327 - val_mse: 31.9663\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 31.1951 - mse: 30.7573 - val_loss: 37.2123 - val_mse: 31.9459\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 31.0079 - mse: 30.6104 - val_loss: 37.3013 - val_mse: 32.8594\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 30.7623 - mse: 31.3044 - val_loss: 38.4459 - val_mse: 32.2315\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 30.5826 - mse: 30.5147 - val_loss: 37.2568 - val_mse: 31.5252\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 29.5227 - mse: 29.7221 - val_loss: 37.6210 - val_mse: 31.6777\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 30.5470 - mse: 30.5482 - val_loss: 39.9837 - val_mse: 36.8088\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 30.0549 - mse: 30.3468 - val_loss: 35.4551 - val_mse: 30.5955\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.6825 - mse: 30.0544 - val_loss: 35.9634 - val_mse: 30.6515\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.6097 - mse: 29.9259 - val_loss: 36.6492 - val_mse: 31.1719\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.2570 - mse: 28.7631 - val_loss: 35.2916 - val_mse: 30.4187\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.2530 - mse: 29.1170 - val_loss: 35.8574 - val_mse: 32.0789\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 28.5930 - mse: 29.1996 - val_loss: 36.6450 - val_mse: 31.2667\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.0112 - mse: 29.3704 - val_loss: 34.6788 - val_mse: 29.8385\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.1168 - mse: 29.4263 - val_loss: 34.7380 - val_mse: 29.8759\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 29.6814 - mse: 29.4187 - val_loss: 34.2020 - val_mse: 29.6353\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 28.4095 - mse: 27.9401 - val_loss: 34.6405 - val_mse: 30.0733\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.3680 - mse: 29.6333 - val_loss: 33.9973 - val_mse: 29.7239\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 30.1689 - mse: 29.7721 - val_loss: 43.8944 - val_mse: 37.6023\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 28.7606 - mse: 29.1102 - val_loss: 38.4432 - val_mse: 33.0119\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 28.5106 - mse: 28.6299 - val_loss: 33.6760 - val_mse: 29.8317\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.7958 - mse: 27.9759 - val_loss: 33.0995 - val_mse: 29.0628\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.3151 - mse: 28.8534 - val_loss: 33.4185 - val_mse: 29.6281\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 30.0379 - mse: 30.0937 - val_loss: 33.2647 - val_mse: 29.4701\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.8838 - mse: 28.3220 - val_loss: 33.5863 - val_mse: 29.2853\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 27.6081 - mse: 27.4162 - val_loss: 33.3586 - val_mse: 29.6783\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 28.4465 - mse: 28.7773 - val_loss: 37.0858 - val_mse: 32.1958\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 27.4560 - mse: 27.8495 - val_loss: 32.5465 - val_mse: 28.6464\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.7309 - mse: 27.8135 - val_loss: 33.6961 - val_mse: 29.4526\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.3955 - mse: 27.4347 - val_loss: 32.5557 - val_mse: 28.5829\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.1875 - mse: 27.0550 - val_loss: 32.2701 - val_mse: 28.4639\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 27.2609 - mse: 27.0698 - val_loss: 32.4802 - val_mse: 28.8429\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 26.3791 - mse: 26.8252 - val_loss: 35.1560 - val_mse: 30.8613\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 26.9291 - mse: 26.7048 - val_loss: 32.0241 - val_mse: 28.3896\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 26.8169 - mse: 26.3692 - val_loss: 32.9385 - val_mse: 29.3336\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 26.0532 - mse: 26.1208 - val_loss: 31.8411 - val_mse: 28.1873\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 27.1319 - mse: 26.6472 - val_loss: 33.3538 - val_mse: 29.7216\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 30.1811 - mse: 30.0089 - val_loss: 31.9910 - val_mse: 28.4085\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 27.0750 - mse: 27.1468 - val_loss: 32.3206 - val_mse: 28.7230\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.2615 - mse: 25.5332 - val_loss: 32.0814 - val_mse: 28.3558\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.6727 - mse: 26.1904 - val_loss: 33.3858 - val_mse: 29.5126\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.5267 - mse: 25.3261 - val_loss: 31.8031 - val_mse: 28.0354\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.4587 - mse: 25.7009 - val_loss: 34.8389 - val_mse: 30.8448\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 26.6483 - mse: 25.8864 - val_loss: 32.8856 - val_mse: 28.9907\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 25.2490 - mse: 25.1185 - val_loss: 32.1039 - val_mse: 28.2698\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.6290 - mse: 25.6286 - val_loss: 31.4966 - val_mse: 27.7332\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.7824 - mse: 25.1482 - val_loss: 31.5027 - val_mse: 27.7089\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.2772 - mse: 25.5366 - val_loss: 31.7705 - val_mse: 27.9467\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.9561 - mse: 24.8927 - val_loss: 31.1640 - val_mse: 27.4217\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24.5150 - mse: 24.9063 - val_loss: 31.0833 - val_mse: 27.2963\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24.3386 - mse: 24.5279 - val_loss: 30.9886 - val_mse: 27.2170\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.4367 - mse: 24.6260 - val_loss: 30.9313 - val_mse: 27.1796\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.5045 - mse: 25.3007 - val_loss: 33.3518 - val_mse: 29.6061\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.2380 - mse: 24.0043 - val_loss: 30.9326 - val_mse: 27.2285\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.8359 - mse: 25.0687 - val_loss: 30.7332 - val_mse: 27.0334\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.5888 - mse: 24.7700 - val_loss: 30.6321 - val_mse: 26.9322\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 24.7188 - mse: 24.7303 - val_loss: 31.3922 - val_mse: 27.7468\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.2257 - mse: 25.3666 - val_loss: 31.0998 - val_mse: 27.4219\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23.6802 - mse: 24.0656 - val_loss: 30.5139 - val_mse: 26.7010\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24.9706 - mse: 23.9071 - val_loss: 30.5613 - val_mse: 26.8105\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 23.6300 - mse: 23.7509 - val_loss: 31.6501 - val_mse: 28.0445\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22.7611 - mse: 22.5985 - val_loss: 30.4634 - val_mse: 26.6755\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24.2422 - mse: 23.3306 - val_loss: 34.9560 - val_mse: 30.4007\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 23.5168 - mse: 23.8029 - val_loss: 33.3192 - val_mse: 29.7536\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 25.1837 - mse: 25.2008 - val_loss: 30.6493 - val_mse: 26.6663\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22.9050 - mse: 23.2028 - val_loss: 32.6477 - val_mse: 29.0526\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 24.6576 - mse: 24.8193 - val_loss: 30.4160 - val_mse: 26.4892\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 23.3086 - mse: 23.2363 - val_loss: 31.4685 - val_mse: 27.8865\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 23.4208 - mse: 23.2485 - val_loss: 30.3193 - val_mse: 26.5034\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23.8382 - mse: 23.4884 - val_loss: 34.5862 - val_mse: 29.8283\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23.0401 - mse: 23.2979 - val_loss: 31.3709 - val_mse: 27.7788\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22.0678 - mse: 22.1652 - val_loss: 30.3176 - val_mse: 26.5790\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 23.1368 - mse: 23.1629 - val_loss: 30.8697 - val_mse: 27.1856\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 23.1143 - mse: 23.2458 - val_loss: 30.3194 - val_mse: 26.4674\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 21.8388 - mse: 21.7196 - val_loss: 30.1725 - val_mse: 26.2174\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22.3191 - mse: 22.2579 - val_loss: 30.2397 - val_mse: 26.4079\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22.5623 - mse: 22.6768 - val_loss: 33.0657 - val_mse: 29.3995\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22.4233 - mse: 21.7271 - val_loss: 40.9747 - val_mse: 35.0163\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 22.7111 - mse: 22.7416 - val_loss: 31.2613 - val_mse: 26.7107\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.8490 - mse: 21.1436 - val_loss: 30.5236 - val_mse: 26.4634\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 21.2855 - mse: 21.1100 - val_loss: 31.2430 - val_mse: 27.2445\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21.7837 - mse: 21.2818 - val_loss: 32.2527 - val_mse: 27.3797\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.4902 - mse: 20.8374 - val_loss: 31.0369 - val_mse: 27.0801\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 20.3616 - mse: 20.5019 - val_loss: 30.4917 - val_mse: 26.1360\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 21.2250 - mse: 20.6998 - val_loss: 35.0272 - val_mse: 29.2260\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.9039 - mse: 20.8891 - val_loss: 33.5276 - val_mse: 29.8145\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 21.4979 - mse: 21.6615 - val_loss: 33.1217 - val_mse: 29.2577\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 20.2024 - mse: 20.2207 - val_loss: 30.9763 - val_mse: 26.1260\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 20.2327 - mse: 20.0043 - val_loss: 34.6308 - val_mse: 28.6107\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.3588 - mse: 20.5447 - val_loss: 32.3407 - val_mse: 28.4911\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.6626 - mse: 19.9868 - val_loss: 31.5059 - val_mse: 27.4937\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.8959 - mse: 20.0945 - val_loss: 30.6933 - val_mse: 26.0419\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.8918 - mse: 19.5796 - val_loss: 32.2143 - val_mse: 26.6802\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 20.2802 - mse: 20.3543 - val_loss: 34.2053 - val_mse: 28.0586\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.0469 - mse: 19.5708 - val_loss: 33.8201 - val_mse: 27.7149\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 22.2570 - mse: 22.4298 - val_loss: 31.2750 - val_mse: 26.7005\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.2577 - mse: 19.5288 - val_loss: 30.9676 - val_mse: 26.0346\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.7926 - mse: 20.5812 - val_loss: 33.7956 - val_mse: 29.8085\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 20.1502 - mse: 20.1066 - val_loss: 30.5999 - val_mse: 25.8465\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.6786 - mse: 19.5529 - val_loss: 33.1562 - val_mse: 27.0229\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.3155 - mse: 19.4996 - val_loss: 32.4648 - val_mse: 28.1200\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 19.1485 - mse: 18.9851 - val_loss: 31.8231 - val_mse: 27.2149\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.9608 - mse: 18.7162 - val_loss: 31.7756 - val_mse: 26.5151\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 18.7214 - mse: 18.7492 - val_loss: 33.1447 - val_mse: 28.5350\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 19.4683 - mse: 19.4714 - val_loss: 31.7045 - val_mse: 26.1936\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.0243 - mse: 18.1644 - val_loss: 32.6900 - val_mse: 27.6833\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.0964 - mse: 18.3753 - val_loss: 32.6103 - val_mse: 27.6776\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 18.9854 - mse: 19.0142 - val_loss: 34.5149 - val_mse: 30.0909\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 18.4182 - mse: 18.6105 - val_loss: 36.2425 - val_mse: 28.4473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f14705a1e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5OIfLVwLmU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7ab8380d-f965-43c8-a9a6-1e768306ef40"
      },
      "source": [
        "''' visualizing... '''\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "log = model.history.history\n",
        "\n",
        "plt.plot(log['loss'], label='train loss')\n",
        "plt.plot(log['val_loss'], label='validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('mean squared error')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'mean squared error')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SfcFnOONyuNm"
      },
      "source": [
        "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
        "\n",
        "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
        "- Make sure to one-hot encode your category labels\n",
        "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
        "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
        "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
        "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szi6-IpuzaH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "04919400-a725-4135-e277-997f20fe4bb2"
      },
      "source": [
        "''' Load and preprocess the image data similar to how we preprocessed the MNIST data in class. '''\n",
        "\n",
        "(xtrain, ytrain), (xtest, ytest) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADnEKp4pNj1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Make sure to one-hot encode your category labels '''\n",
        "\n",
        "ytrain = tf.keras.utils.to_categorical(ytrain)\n",
        "ytest = tf.keras.utils.to_categorical(ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2cqfaaoN_iF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a2f3dd0-3bd5-4ccf-9f3d-2f87fb3e663d"
      },
      "source": [
        "''' The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST. '''\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(784, activation='selu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='selu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='selu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=xtrain, y=ytrain, epochs=32, validation_data=(xtest, ytest))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.6292 - accuracy: 0.7904 - val_loss: 0.4583 - val_accuracy: 0.8354\n",
            "Epoch 2/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4541 - accuracy: 0.8395 - val_loss: 0.4184 - val_accuracy: 0.8547\n",
            "Epoch 3/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4347 - accuracy: 0.8466 - val_loss: 0.4548 - val_accuracy: 0.8459\n",
            "Epoch 4/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4223 - accuracy: 0.8511 - val_loss: 0.4473 - val_accuracy: 0.8488\n",
            "Epoch 5/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4182 - accuracy: 0.8558 - val_loss: 0.4269 - val_accuracy: 0.8483\n",
            "Epoch 6/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3971 - accuracy: 0.8640 - val_loss: 0.4236 - val_accuracy: 0.8552\n",
            "Epoch 7/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3777 - accuracy: 0.8694 - val_loss: 0.5240 - val_accuracy: 0.8328\n",
            "Epoch 8/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3828 - accuracy: 0.8693 - val_loss: 0.4329 - val_accuracy: 0.8638\n",
            "Epoch 9/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4184 - accuracy: 0.8734 - val_loss: 0.4955 - val_accuracy: 0.8341\n",
            "Epoch 10/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4168 - accuracy: 0.8773 - val_loss: 0.4818 - val_accuracy: 0.8579\n",
            "Epoch 11/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4132 - accuracy: 0.8769 - val_loss: 0.4520 - val_accuracy: 0.8521\n",
            "Epoch 12/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3444 - accuracy: 0.8827 - val_loss: 0.4713 - val_accuracy: 0.8573\n",
            "Epoch 13/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3368 - accuracy: 0.8852 - val_loss: 0.3754 - val_accuracy: 0.8739\n",
            "Epoch 14/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3354 - accuracy: 0.8867 - val_loss: 0.4258 - val_accuracy: 0.8673\n",
            "Epoch 15/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3331 - accuracy: 0.8865 - val_loss: 0.4791 - val_accuracy: 0.8522\n",
            "Epoch 16/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3657 - accuracy: 0.8847 - val_loss: 0.4141 - val_accuracy: 0.8710\n",
            "Epoch 17/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3114 - accuracy: 0.8943 - val_loss: 0.4410 - val_accuracy: 0.8682\n",
            "Epoch 18/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3176 - accuracy: 0.8930 - val_loss: 0.3664 - val_accuracy: 0.8791\n",
            "Epoch 19/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3182 - accuracy: 0.8944 - val_loss: 0.4591 - val_accuracy: 0.8660\n",
            "Epoch 20/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3127 - accuracy: 0.8954 - val_loss: 0.4512 - val_accuracy: 0.8751\n",
            "Epoch 21/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3908 - accuracy: 0.8944 - val_loss: 0.4983 - val_accuracy: 0.8391\n",
            "Epoch 22/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3097 - accuracy: 0.8962 - val_loss: 0.4973 - val_accuracy: 0.8695\n",
            "Epoch 23/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3100 - accuracy: 0.8984 - val_loss: 0.4873 - val_accuracy: 0.8657\n",
            "Epoch 24/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2897 - accuracy: 0.9018 - val_loss: 0.5324 - val_accuracy: 0.8616\n",
            "Epoch 25/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3001 - accuracy: 0.9007 - val_loss: 0.5524 - val_accuracy: 0.8537\n",
            "Epoch 26/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3061 - accuracy: 0.8999 - val_loss: 0.4895 - val_accuracy: 0.8676\n",
            "Epoch 27/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2939 - accuracy: 0.9019 - val_loss: 0.6773 - val_accuracy: 0.8655\n",
            "Epoch 28/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3015 - accuracy: 0.9028 - val_loss: 1.4498 - val_accuracy: 0.8635\n",
            "Epoch 29/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2883 - accuracy: 0.9050 - val_loss: 0.9947 - val_accuracy: 0.8794\n",
            "Epoch 30/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4173 - accuracy: 0.9032 - val_loss: 1.1395 - val_accuracy: 0.7527\n",
            "Epoch 31/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3179 - accuracy: 0.9018 - val_loss: 0.9105 - val_accuracy: 0.8650\n",
            "Epoch 32/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2997 - accuracy: 0.9091 - val_loss: 0.5349 - val_accuracy: 0.8797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1470173d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXp2VHLoRSai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fc4a666-0360-481c-e09a-6b0947987f48"
      },
      "source": [
        "''' The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST. '''\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=xtrain, y=ytrain, epochs=32, validation_data=(xtest, ytest))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.5036 - accuracy: 0.7889 - val_loss: 0.4859 - val_accuracy: 0.8245\n",
            "Epoch 2/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4364 - accuracy: 0.8443 - val_loss: 0.4853 - val_accuracy: 0.8314\n",
            "Epoch 3/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3998 - accuracy: 0.8562 - val_loss: 0.4113 - val_accuracy: 0.8515\n",
            "Epoch 4/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3835 - accuracy: 0.8625 - val_loss: 0.3971 - val_accuracy: 0.8598\n",
            "Epoch 5/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3725 - accuracy: 0.8680 - val_loss: 0.4221 - val_accuracy: 0.8572\n",
            "Epoch 6/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3566 - accuracy: 0.8723 - val_loss: 0.3936 - val_accuracy: 0.8647\n",
            "Epoch 7/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3477 - accuracy: 0.8771 - val_loss: 0.4097 - val_accuracy: 0.8673\n",
            "Epoch 8/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3310 - accuracy: 0.8824 - val_loss: 0.4361 - val_accuracy: 0.8600\n",
            "Epoch 9/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3268 - accuracy: 0.8842 - val_loss: 0.4647 - val_accuracy: 0.8480\n",
            "Epoch 10/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3156 - accuracy: 0.8882 - val_loss: 0.4050 - val_accuracy: 0.8641\n",
            "Epoch 11/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3147 - accuracy: 0.8887 - val_loss: 0.4257 - val_accuracy: 0.8577\n",
            "Epoch 12/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3019 - accuracy: 0.8921 - val_loss: 0.3834 - val_accuracy: 0.8709\n",
            "Epoch 13/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2914 - accuracy: 0.8950 - val_loss: 0.4310 - val_accuracy: 0.8664\n",
            "Epoch 14/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2958 - accuracy: 0.8960 - val_loss: 0.4332 - val_accuracy: 0.8669\n",
            "Epoch 15/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2893 - accuracy: 0.8966 - val_loss: 0.4106 - val_accuracy: 0.8722\n",
            "Epoch 16/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2901 - accuracy: 0.8970 - val_loss: 0.4030 - val_accuracy: 0.8773\n",
            "Epoch 17/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2935 - accuracy: 0.8974 - val_loss: 0.3867 - val_accuracy: 0.8792\n",
            "Epoch 18/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2804 - accuracy: 0.9011 - val_loss: 0.4501 - val_accuracy: 0.8702\n",
            "Epoch 19/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2741 - accuracy: 0.9029 - val_loss: 0.3806 - val_accuracy: 0.8672\n",
            "Epoch 20/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2839 - accuracy: 0.9005 - val_loss: 0.3994 - val_accuracy: 0.8735\n",
            "Epoch 21/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2747 - accuracy: 0.9038 - val_loss: 0.4009 - val_accuracy: 0.8779\n",
            "Epoch 22/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2665 - accuracy: 0.9050 - val_loss: 0.4555 - val_accuracy: 0.8673\n",
            "Epoch 23/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2685 - accuracy: 0.9044 - val_loss: 0.4086 - val_accuracy: 0.8769\n",
            "Epoch 24/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2602 - accuracy: 0.9069 - val_loss: 0.4233 - val_accuracy: 0.8747\n",
            "Epoch 25/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2666 - accuracy: 0.9065 - val_loss: 0.4034 - val_accuracy: 0.8777\n",
            "Epoch 26/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2583 - accuracy: 0.9082 - val_loss: 0.4042 - val_accuracy: 0.8763\n",
            "Epoch 27/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2539 - accuracy: 0.9097 - val_loss: 0.4236 - val_accuracy: 0.8812\n",
            "Epoch 28/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2577 - accuracy: 0.9098 - val_loss: 0.4055 - val_accuracy: 0.8826\n",
            "Epoch 29/32\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2715 - accuracy: 0.9068 - val_loss: 0.4347 - val_accuracy: 0.8767\n",
            "Epoch 30/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2463 - accuracy: 0.9131 - val_loss: 0.4647 - val_accuracy: 0.8743\n",
            "Epoch 31/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2428 - accuracy: 0.9136 - val_loss: 0.4766 - val_accuracy: 0.8822\n",
            "Epoch 32/32\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2606 - accuracy: 0.9111 - val_loss: 0.5579 - val_accuracy: 0.8697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f144255dc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6H4qdtMRj-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e66cbe75-78ba-4b86-9f90-4e2bcd53933c"
      },
      "source": [
        "''' The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST. '''\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x=xtrain, y=ytrain, epochs=32, validation_data=(xtest, ytest))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1160 - accuracy: 0.7926 - val_loss: 0.5047 - val_accuracy: 0.8134\n",
            "Epoch 2/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4303 - accuracy: 0.8467 - val_loss: 0.4279 - val_accuracy: 0.8457\n",
            "Epoch 3/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3967 - accuracy: 0.8597 - val_loss: 0.4015 - val_accuracy: 0.8570\n",
            "Epoch 4/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3783 - accuracy: 0.8675 - val_loss: 0.4345 - val_accuracy: 0.8553\n",
            "Epoch 5/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3672 - accuracy: 0.8710 - val_loss: 0.3926 - val_accuracy: 0.8632\n",
            "Epoch 6/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3456 - accuracy: 0.8775 - val_loss: 0.4190 - val_accuracy: 0.8596\n",
            "Epoch 7/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3359 - accuracy: 0.8815 - val_loss: 0.3552 - val_accuracy: 0.8787\n",
            "Epoch 8/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3222 - accuracy: 0.8854 - val_loss: 0.3728 - val_accuracy: 0.8737\n",
            "Epoch 9/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3119 - accuracy: 0.8882 - val_loss: 0.3952 - val_accuracy: 0.8684\n",
            "Epoch 10/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3138 - accuracy: 0.8895 - val_loss: 0.3957 - val_accuracy: 0.8712\n",
            "Epoch 11/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3081 - accuracy: 0.8916 - val_loss: 0.4029 - val_accuracy: 0.8774\n",
            "Epoch 12/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2988 - accuracy: 0.8946 - val_loss: 0.4515 - val_accuracy: 0.8640\n",
            "Epoch 13/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2960 - accuracy: 0.8953 - val_loss: 0.4475 - val_accuracy: 0.8597\n",
            "Epoch 14/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2993 - accuracy: 0.8942 - val_loss: 0.4081 - val_accuracy: 0.8713\n",
            "Epoch 15/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2860 - accuracy: 0.8978 - val_loss: 0.4002 - val_accuracy: 0.8759\n",
            "Epoch 16/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2776 - accuracy: 0.9008 - val_loss: 0.3866 - val_accuracy: 0.8796\n",
            "Epoch 17/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2862 - accuracy: 0.9007 - val_loss: 0.3705 - val_accuracy: 0.8779\n",
            "Epoch 18/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2759 - accuracy: 0.9024 - val_loss: 0.3983 - val_accuracy: 0.8792\n",
            "Epoch 19/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2726 - accuracy: 0.9020 - val_loss: 0.3751 - val_accuracy: 0.8788\n",
            "Epoch 20/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2688 - accuracy: 0.9033 - val_loss: 0.3931 - val_accuracy: 0.8861\n",
            "Epoch 21/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2688 - accuracy: 0.9047 - val_loss: 0.3933 - val_accuracy: 0.8768\n",
            "Epoch 22/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2512 - accuracy: 0.9082 - val_loss: 0.4467 - val_accuracy: 0.8797\n",
            "Epoch 23/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2788 - accuracy: 0.9047 - val_loss: 0.3921 - val_accuracy: 0.8813\n",
            "Epoch 24/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2482 - accuracy: 0.9102 - val_loss: 0.4225 - val_accuracy: 0.8819\n",
            "Epoch 25/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2559 - accuracy: 0.9091 - val_loss: 0.4559 - val_accuracy: 0.8864\n",
            "Epoch 26/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2506 - accuracy: 0.9115 - val_loss: 0.4956 - val_accuracy: 0.8800\n",
            "Epoch 27/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2814 - accuracy: 0.9076 - val_loss: 0.4412 - val_accuracy: 0.8806\n",
            "Epoch 28/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2933 - accuracy: 0.9074 - val_loss: 0.4500 - val_accuracy: 0.8736\n",
            "Epoch 29/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2478 - accuracy: 0.9114 - val_loss: 0.4166 - val_accuracy: 0.8791\n",
            "Epoch 30/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2491 - accuracy: 0.9131 - val_loss: 0.4346 - val_accuracy: 0.8831\n",
            "Epoch 31/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2368 - accuracy: 0.9163 - val_loss: 0.5962 - val_accuracy: 0.8753\n",
            "Epoch 32/32\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2553 - accuracy: 0.9118 - val_loss: 0.4511 - val_accuracy: 0.8760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f14420b24a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Scju7lVuyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4ade7ae0-b94d-4463-ff05-b150bd0c7938"
      },
      "source": [
        "history = model.history.history\n",
        "plt.plot(history['loss'], label='training loss')\n",
        "plt.plot(history['val_loss'], label='validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewFqUplZWfSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "ab1a1730-d7bd-4eb2-bc5d-03b0d7726ca6"
      },
      "source": [
        "''' The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST. '''\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(784, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(375, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(150, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['categorical_accuracy'])\n",
        "\n",
        "model.fit(x=xtrain, y=ytrain, epochs=16, validation_data=(xtest, ytest))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.1543 - categorical_accuracy: 0.8010 - val_loss: 0.4741 - val_categorical_accuracy: 0.8343\n",
            "Epoch 2/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4225 - categorical_accuracy: 0.8488 - val_loss: 0.4753 - val_categorical_accuracy: 0.8294\n",
            "Epoch 3/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3958 - categorical_accuracy: 0.8588 - val_loss: 0.3963 - val_categorical_accuracy: 0.8573\n",
            "Epoch 4/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3718 - categorical_accuracy: 0.8674 - val_loss: 0.4037 - val_categorical_accuracy: 0.8607\n",
            "Epoch 5/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3555 - categorical_accuracy: 0.8720 - val_loss: 0.3740 - val_categorical_accuracy: 0.8739\n",
            "Epoch 6/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3374 - categorical_accuracy: 0.8797 - val_loss: 0.4087 - val_categorical_accuracy: 0.8663\n",
            "Epoch 7/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3321 - categorical_accuracy: 0.8826 - val_loss: 0.3900 - val_categorical_accuracy: 0.8687\n",
            "Epoch 8/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3174 - categorical_accuracy: 0.8872 - val_loss: 0.3663 - val_categorical_accuracy: 0.8741\n",
            "Epoch 9/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3100 - categorical_accuracy: 0.8886 - val_loss: 0.4067 - val_categorical_accuracy: 0.8658\n",
            "Epoch 10/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3046 - categorical_accuracy: 0.8922 - val_loss: 0.4141 - val_categorical_accuracy: 0.8612\n",
            "Epoch 11/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2981 - categorical_accuracy: 0.8927 - val_loss: 0.3570 - val_categorical_accuracy: 0.8788\n",
            "Epoch 12/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2990 - categorical_accuracy: 0.8945 - val_loss: 0.3722 - val_categorical_accuracy: 0.8752\n",
            "Epoch 13/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2826 - categorical_accuracy: 0.8990 - val_loss: 0.3863 - val_categorical_accuracy: 0.8759\n",
            "Epoch 14/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2778 - categorical_accuracy: 0.8998 - val_loss: 0.3817 - val_categorical_accuracy: 0.8740\n",
            "Epoch 15/16\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2804 - categorical_accuracy: 0.9007 - val_loss: 0.4236 - val_categorical_accuracy: 0.8744\n",
            "Epoch 16/16\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2707 - categorical_accuracy: 0.9032 - val_loss: 0.4103 - val_categorical_accuracy: 0.8768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1430cd3358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh5VvtPyY2XF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6334fe2d-5abd-4f5e-a56a-db918e9866f3"
      },
      "source": [
        "history = model.history.history\n",
        "plt.plot(history['loss'], label='training loss')\n",
        "plt.plot(history['val_loss'], label='validation loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRszBwuNY2tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
        "- Use Cross Validation techniques to get more consistent results with your model.\n",
        "- Use GridSearchCV to try different combinations of hyperparameters. \n",
        "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
      ]
    }
  ]
}